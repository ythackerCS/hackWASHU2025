<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.1.1.min.js" integrity="sha256-HUEFyfiTnZJxCxur99FjbKYTvKSzwDaD3/x5TqHpFu4=" crossorigin="anonymous"></script>                <div id="139b0baa-7865-4838-a20f-39d2403a3dd9" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("139b0baa-7865-4838-a20f-39d2403a3dd9")) {                    Plotly.newPlot(                        "139b0baa-7865-4838-a20f-39d2403a3dd9",                        [{"hoverinfo":"none","line":{"color":"rgba(120,120,120,0.5)","width":1},"mode":"lines","x":[],"y":[],"type":"scatter"},{"hovertext":["\u003cb\u003eVery Deep Convolutional Networks for Large-Scale Image Recognition\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eImageNet: A large-scale hierarchical image database\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.2009.5206848\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eVery Deep Convolutional Networks for Large-Scale Image Recognition\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.1409.1556\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDeep Learning\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eTensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.1603.04467\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eYOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr52729.2023.00721\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eProceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1145\u002f2939672\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eAn experimental comparison of min-cut\u002fmax- flow algorithms for energy minimization in vision\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2004.60\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eReading Digits in Natural Images with Unsupervised Feature Learning\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eSegment Anything\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ficcv51070.2023.00371\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision: algorithms and applications\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.5860\u002fchoice.48-5140\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eOnline Object Tracking: A Benchmark\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.2013.312\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEmbedded Autonomy\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1515\u002f9781400821723\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eRobot Vision\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEmbedded autonomy: states and industrial transformation\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.5860\u002fchoice.33-1763\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eHMDB: A large video database for human motion recognition\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ficcv.2011.6126543\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDetecting faces in images: a survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002f34.982883\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA tutorial on visual servo control\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002f70.538972\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEfficient Processing of Deep Neural Networks: A Tutorial and Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fjproc.2017.2761740\u003cbr\u003eTotal shared refs: 0","\u003cb\u003ePyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ficcv48922.2021.00061\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eGeometric Deep Learning: Going beyond Euclidean data\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fmsp.2017.2693418\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eObject Tracking Benchmark\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2014.2388226\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eImage Correlation for Shape, Motion and Deformation Measurements: Basic Concepts,Theory and Applications\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eShape modeling with front propagation: a level set approach\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002f34.368173\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eWhat energy functions can be minimized via graph cuts?\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2004.1262177\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eImageNet: A large-scale hierarchical image database\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvprw.2009.5206848\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eImage Segmentation Using Deep Learning: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2021.3059968\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eSUN database: Large-scale scene recognition from abbey to zoo\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.2010.5539970\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eAn End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2016.2646371\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eVlfeat\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1145\u002f1873951.1874249\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eShapeNet: An Information-Rich 3D Model Repository\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.1512.03012\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA Survey on Vision Transformer\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2022.3152247\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eThe symbolic species: the co-evolution of language and the brain\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.5860\u002fchoice.35-1500\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDeep Learning for Generic Object Detection: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs11263-019-01247-4\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDOTA: A Large-Scale Dataset for Object Detection in Aerial Images\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.2018.00418\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eFoundations of Cyclopean Perception\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.2307\u002f1421958\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eOverview of the Face Recognition Grand Challenge\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.2005.268\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eTransformers in Vision: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1145\u002f3505244\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eVision Science: Photons to Phenomenology\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eLearning from imbalanced data: open challenges and future directions\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs13748-016-0094-0\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eHuman activity analysis\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1145\u002f1922649.1922653\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eThreat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002faccess.2018.2807385\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eObject Detection in 20 Years: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fjproc.2023.3238524\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eImage And Brain\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.7551\u002fmitpress\u002f3653.001.0001\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eVisual interpretation of hand gestures for human-computer interaction: a review\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002f34.598226\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDeep Learning for 3D Point Clouds: A Survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftpami.2020.3005434\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eAttention mechanisms in computer vision: A survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs41095-022-0271-y\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eOpenFace 2.0: Facial Behavior Analysis Toolkit\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ffg.2018.00019\u003cbr\u003eTotal shared refs: 0","\u003cb\u003ePerception as Bayesian Inference\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1017\u002fcbo9780511984037\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eOpenFace: An open source facial behavior analysis toolkit\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fwacv.2016.7477553\u003cbr\u003eTotal shared refs: 0","\u003cb\u003ePVT v2: Improved baselines with Pyramid Vision Transformer\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs41095-022-0274-8\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEnhanced Computer Vision With Microsoft Kinect Sensor: A Review\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftcyb.2013.2265378\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDeepGlobe 2018: A Challenge to Parse the Earth through Satellite Images\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvprw.2018.00031\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eGeometric Partial Differential Equations and Image Analysis\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1017\u002fcbo9780511626319\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eFace Recognition by Humans: Nineteen Results All Computer Vision Researchers Should Know About\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fjproc.2006.884093\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA Spontaneous Micro-expression Database: Inducement, collection and baseline\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ffg.2013.6553717\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eAdversarial Attacks on Deep-learning Models in Natural Language Processing\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1145\u002f3374217\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eShape Analysis of Agricultural Products: A Review of Recent Research Advances and Potential Application to Computer Vision\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs11947-011-0556-0\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eAge classification from facial images\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.1994.323894\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision for sports: Current applications and research topics\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.cviu.2017.04.011\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer Vision, IoT and Data Fusion for Crop Disease Detection Using Machine Learning: A Survey and Ongoing Research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.3390\u002frs13132486\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision for wildfire research: An evolving image dataset for processing and analysis\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.firesaf.2017.06.012\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision for solid waste sorting: A critical review of academic research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.wasman.2022.02.009\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision technologies for safety science and management in construction: A critical review and future research directions\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.ssci.2020.105130\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA Comprehensive Review of Computer Vision in Sports: Open Issues, Future Trends and Research Directions\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.3390\u002fapp12094429\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision-based interior construction progress monitoring: A literature review and future research directions\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.autcon.2021.103705\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision in autism spectrum disorder research: a systematic review of published studies from 2009 to 2019\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1038\u002fs41398-020-01015-w\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eHoloLens 2 Research Mode as a Tool for Computer Vision Research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.2008.11239\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eApplications of Computer Vision for Assessing Quality of Agri-food Products: A Review of Recent Research Advances\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1080\u002f10408398.2013.873885\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eMapping computer vision research in construction: Developments, knowledge gaps and implications for research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.autcon.2019.102919\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eApplications, databases and open computer vision research from drone videos and images: a survey\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs10462-020-09943-1\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eResearch on computer vision-based for UAV autonomous landing on a ship\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.patrec.2008.12.011\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eSignStream: A tool for linguistic and computer vision research on visual-gestural language data\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.3758\u002fbf03195384\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA survey on GANs for computer vision: Recent research, analysis and taxonomy\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.cosrev.2023.100553\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eOverhead imagery research data set &amp;#x2014; an annotated data library &amp;#x00026; tools to aid in the development of computer vision algorithms\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002faipr.2009.5466304\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eVista: a software environment for computer vision research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr.1994.323895\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA review of the research and application of deep learning-based computer vision in structural damage detection\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs11803-022-2074-7\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eApplying a 6-axis Mechanical Arm Combine with Computer Vision to the Research of Object Recognition in Plane Inspection\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.36548\u002fjaicn.2020.2.002\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eDARWIN: a framework for machine learning and computer vision research and development\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eCemrgApp: An interactive medical imaging application with image processing, computer vision, and machine learning toolkits for cardiovascular research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.softx.2020.100570\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eBrain-computer interaction research at the computer vision and multimedia laboratory, University of Geneva\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftnsre.2006.875544\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eResearch on Remote Meter Automatic Reading Based on Computer Vision\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002ftdc.2005.1546972\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer-vision-based research on friction vibration and coupling of frictional and torsional vibrations in water-lubricated bearing-shaft system\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.triboint.2020.106336\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eResearch on weld pool control of welding robot with computer vision\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1108\u002f01439910710832066\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eCurrent research opportunities of image processing and computer vision\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.7494\u002fcsci.2019.20.4.3163\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eResearch on Image Processing Technology of Computer Vision Algorithm\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvidl51233.2020.00030\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eConsumer Depth Cameras for Computer Vision: Research Topics and Applications\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEnhancing camera surveillance using computer vision: a research note\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1108\u002fpijpsm-11-2016-0158\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer Vision to Enhance Behavioral Research on Insects\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1093\u002faesa\u002fsay062\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision and IoT research landscape for health and safety management on construction sites\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.jobe.2023.107049\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eResearch progress of computer vision technology in abnormal fish detection\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1016\u002fj.aquaeng.2023.102350\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eSCENIC: A JAX Library for Computer Vision Research and Beyond\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1109\u002fcvpr52688.2022.02070\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eArch2030: A Vision of Computer Architecture Research over the Next 15 Years\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.1612.03182\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision-aided bioprinting for bone research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1038\u002fs41413-022-00192-2\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer vision quantization research on the architectural color of Avenida de Almeida Ribeiro in Macau based on the human eye perspective\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.3389\u002ffncom.2022.951718\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eA survey on GANs for computer vision: Recent research, analysis and taxonomy\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.48550\u002farxiv.2203.11242\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eComputer Vision Based Research on PCB Recognition Using SSD Neural Network\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1088\u002f1742-6596\u002f1815\u002f1\u002f012005\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eEnhancing camera surveillance using computer vision: a research note.\u003c\u002fb\u003e\u003cbr\u003eDOI: None\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eArt \u2013 A Perfect Testbed for Computer Vision Related Research\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002f978-3-642-02900-4_23\u003cbr\u003eTotal shared refs: 0","\u003cb\u003eRETRACTED ARTICLE: Underwater image segmentation based on computer vision and research on recognition algorithm\u003c\u002fb\u003e\u003cbr\u003eDOI: 10.1007\u002fs12517-021-08081-4\u003cbr\u003eTotal shared refs: 0"],"marker":{"color":[10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10],"colorbar":{"title":{"text":"Shared References"}},"colorscale":[[0.0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1.0,"rgb(8,48,107)"]],"line":{"width":1},"showscale":true,"size":[10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10]},"mode":"markers","x":[-0.08005807271392336,0.7844308545738883,-0.6904185392325852,-0.8810464120692957,0.24094672668278877,-0.7079086944503616,0.7714288401062775,-0.8064723036948608,-0.6912697618743604,-0.12198119938938015,0.2520876961497738,-0.8755172184339524,-0.008480964965072006,-0.9578502199674236,0.1275816422376437,0.36826941056015766,-0.5482381020916505,0.9050349312668096,-0.47806886467394916,0.8720232204244597,-0.9844898418984809,-0.8216103033326448,-0.5682679521268367,-0.12459294059802861,0.18735581222300335,0.9591013550098582,0.7320791071774208,0.058694747994076625,-0.878419302017574,-0.9819411978588045,-0.4117493881930727,0.9581302925107933,-0.9108204038023312,-0.6363241130126839,-0.3211392290393712,0.5905594139750453,-0.947701164107529,0.5751989291497702,0.4850769564217048,0.002241816129378597,0.9176845458741022,-0.18355059408174124,-0.7143251135963011,0.6671149327843485,0.9913827874659422,-0.8984338941195176,0.9435415310465624,0.9742167661534085,0.9265686139110288,-0.7811484035887947,-0.9672142260353245,-0.9444832032507512,0.9277747727405523,-0.24711974918662286,-0.5908301823978889,-0.6325738321401136,0.777868497971745,0.18226309730862653,0.6465745379530955,0.9907235331036615,0.4348114333563734,-0.3066278420261454,-0.9438490298906715,0.5280914673279833,-1.0,-0.2414851155350758,-0.9424221944243054,0.9912016082651934,0.11633464921644676,-0.1813300290044697,0.9601677307949967,0.6685180224200049,-0.373741420501229,0.8404325202290207,-0.9292756821673882,0.8477246226805297,-0.9762111731764601,0.8935581983521871,0.36273948541362905,-0.47392805412146416,-0.35226691891400247,0.4580309154561858,-0.7661749515213147,-0.5288642360708289,-0.9895266564056124,0.3181353229202935,0.06582471607205637,0.5321310905690433,0.7880970940743703,0.7319617772005613,-0.06347963841997037,0.6429995799498681,-0.8195310216748819,0.9754237307675458,0.4214230736971595,-0.4248042704298426,0.9769781667771107,-0.8158521802581352,0.30600678763986267,0.8468684403966781],"y":[0.9931451217196079,0.5743764713442998,-0.7259984746462209,0.4919991431264695,0.9374080342335955,0.7380755936329764,-0.6346992038105871,-0.5840796618911174,0.6612569200338257,-0.9606704260922406,-0.9580312789631439,-0.41406385138889085,0.9743261545704662,0.18564948680894855,-0.9927931824305628,-0.9152514781373339,0.854683978931837,0.4525806138238405,-0.8753705611589008,-0.4151493242200255,0.056409801626233366,0.5974192577021792,0.7871556580799828,0.9294347205056199,-0.9650846205068705,0.31307198088804106,0.7034652676669386,0.9912691349922322,-0.4857447549604424,-0.1860307565523068,-0.8814017310449256,-0.2385969780126827,0.3174858705507144,0.7660645358087076,0.9609656170386839,-0.7998839809846863,0.34996333345676905,0.7917854602846832,-0.8822939080208945,-0.9882225277101283,0.3713110112711557,-0.9827635915758969,-0.6603816306860241,0.7078557284448053,-0.004943828881110229,0.42262250124308276,0.24913306129470933,-0.06853740563169941,-0.1717393187745334,-0.6527511042042567,0.2532810709470963,-0.010589916761755374,-0.369752712474336,0.9404837159536835,-0.8120034175100376,-0.760767741241426,0.6408913705548547,0.97167818764568,-0.7605522482538681,0.06096947506326713,0.9024971286930021,-0.9465708946077995,-0.24065308550043907,0.849186658711117,-0.042029124079510295,-0.9475401981632934,-0.3072155988960079,-0.1419986393388938,0.9575750027137848,0.9835155351598502,-0.3070502568030179,-0.687567569832473,-0.93387593801535,0.4502112461000663,-0.37524881984822506,-0.5372476880733849,-0.11742165982058814,-0.47674405656375624,0.9087291135631708,0.854314329936651,0.8913708340436921,0.8336077655091393,0.6495144306987662,-0.8322954093379465,0.12555752151447885,-0.9566000600904232,-0.9747651829020011,-0.831497482270524,-0.5677571284739099,-0.7032059019934539,-0.990114532552008,0.7800252289923303,0.5275396902940325,0.12439469955345246,-0.87437696983516,0.9098344197751744,0.1902420082087945,-0.5174624885017137,0.9478550290636822,0.5351993802506098],"type":"scatter"}],                        {"hovermode":"closest","margin":{"b":0,"l":0,"r":0,"t":50},"showlegend":false,"title":{"text":"Co-Citation Network"},"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}}},                        {"responsive": true}                    )                };            </script>        </div>
</body>
</html>