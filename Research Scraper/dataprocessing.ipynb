{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1780e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "OPENALEX_URL = \"https://api.openalex.org/works\"\n",
    "SEMANTIC_SCHOLAR_URL = \"https://api.semanticscholar.org/graph/v1/paper/\"\n",
    "\n",
    "def search_openalex(query, n=10, sort_by=\"cited_by_count\"):\n",
    "    \"\"\"Search OpenAlex and return sorted results by a field (default: citations).\"\"\"\n",
    "    params = {\n",
    "        \"search\": query,\n",
    "        \"per_page\": n,\n",
    "        \"sort\": f\"{sort_by}:desc\"  # descending order\n",
    "    }\n",
    "    r = requests.get(OPENALEX_URL, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    results = r.json().get(\"results\", [])\n",
    "    return results\n",
    "\n",
    "def get_pdf_link(paper):\n",
    "    arxiv_id = paper.get(\"ids\", {}).get(\"arxiv\")\n",
    "    if arxiv_id:\n",
    "        return f\"https://arxiv.org/pdf/{arxiv_id.split('/')[-1]}.pdf\"\n",
    "    return paper.get(\"primary_location\", {}).get(\"landing_page_url\")\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        r = requests.get(url, stream=True, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        content_type = r.headers.get('Content-Type', '')\n",
    "        if 'pdf' not in content_type.lower():\n",
    "            return None\n",
    "        with open(filename, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        return filename\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_full_text_from_pdf(path):\n",
    "    try:\n",
    "        with fitz.open(path) as doc:\n",
    "            return \"\".join([page.get_text(\"text\") + \"\\n\" for page in doc])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_sections_from_pdf(path):\n",
    "    text = extract_full_text_from_pdf(path)\n",
    "    if not text:\n",
    "        return {}\n",
    "    sections = {}\n",
    "    for sec in [\"abstract\", \"introduction\", \"methods\", \"materials and methods\"]:\n",
    "        pattern = re.compile(\n",
    "            rf\"(?i)\\b{sec}\\b[\\s:]*([\\s\\S]*?)(?=\\n[A-Z][^\\n]{{0,60}}\\n|$)\"\n",
    "        )\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            sections[sec.lower()] = match.group(1).strip()\n",
    "    return sections\n",
    "\n",
    "def get_semantic_scholar_abstract(doi_or_title):\n",
    "    try:\n",
    "        if doi_or_title.startswith(\"10.\"):\n",
    "            url = SEMANTIC_SCHOLAR_URL + f\"DOI:{doi_or_title}?fields=title,abstract\"\n",
    "        else:\n",
    "            search_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "            res = requests.get(search_url, params={\"query\": doi_or_title, \"limit\": 1})\n",
    "            data = res.json().get(\"data\", [])\n",
    "            if not data:\n",
    "                return None\n",
    "            paper_id = data[0][\"paperId\"]\n",
    "            url = SEMANTIC_SCHOLAR_URL + f\"{paper_id}?fields=title,abstract\"\n",
    "        res = requests.get(url, timeout=15)\n",
    "        if res.status_code == 200:\n",
    "            return res.json().get(\"abstract\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def find_and_extract(query, n=3, mode=\"sections\", print_output=True):\n",
    "    papers = search_openalex(query, n=n*4, sort_by=\"cited_by_count\")\n",
    "    results = []\n",
    "    success_count = 0\n",
    "    i = 0\n",
    "    paper_index = 1\n",
    "\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    while success_count < n and i < len(papers):\n",
    "        paper = papers[i]\n",
    "        i += 1\n",
    "\n",
    "        title = paper[\"display_name\"]\n",
    "        doi = paper.get(\"doi\", \"\")\n",
    "        citations = paper.get(\"cited_by_count\", 0)\n",
    "        pub_date = paper.get(\"publication_date\", \"N/A\")\n",
    "        publication_year = pub_date.split(\"-\")[0] if pub_date != \"N/A\" else \"N/A\"\n",
    "\n",
    "        authorships = paper.get(\"authorships\", [])\n",
    "        first_author_inst = authorships[0][\"institutions\"][0][\"display_name\"] if authorships and authorships[0][\"institutions\"] else \"N/A\"\n",
    "        last_author_inst = authorships[-1][\"institutions\"][0][\"display_name\"] if authorships and authorships[-1][\"institutions\"] else \"N/A\"\n",
    "        pdf_url = get_pdf_link(paper)\n",
    "\n",
    "        # Extract last 4 years of citations\n",
    "        counts_by_year = {int(c[\"year\"]): c[\"cited_by_count\"] for c in paper.get(\"counts_by_year\", [])}\n",
    "        last_4_years_citations = {str(year): counts_by_year.get(year, 0) for year in range(current_year-3, current_year+1)}\n",
    "\n",
    "        text_data = {\"abstract\": None, \"introduction\": None, \"methods\": None, \"full_text\": None}\n",
    "        extracted_something = False\n",
    "\n",
    "        if mode != \"notext\" and pdf_url:\n",
    "            filename = f\"paper_{paper_index}.pdf\"\n",
    "            downloaded = download_pdf(pdf_url, filename)\n",
    "            if downloaded and os.path.exists(filename):\n",
    "                if mode == \"full\":\n",
    "                    text_data[\"full_text\"] = extract_full_text_from_pdf(filename)\n",
    "                    extracted_something = True\n",
    "                elif mode == \"sections\":\n",
    "                    sections = extract_sections_from_pdf(filename)\n",
    "                    if sections:\n",
    "                        text_data.update({k: sections.get(k) for k in [\"abstract\", \"introduction\", \"methods\"]})\n",
    "                        extracted_something = True\n",
    "                try:\n",
    "                    os.remove(filename)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        if not extracted_something and mode != \"notext\":\n",
    "            abstract = get_semantic_scholar_abstract(doi or title)\n",
    "            if abstract:\n",
    "                text_data[\"abstract\"] = abstract\n",
    "                extracted_something = True\n",
    "\n",
    "        result = {\n",
    "            \"title\": title,\n",
    "            \"doi\": doi,\n",
    "            \"citations_total\": citations,\n",
    "            \"publication_date\": pub_date,\n",
    "            \"publication_year\": publication_year,\n",
    "            \"first_author_institution\": first_author_inst,\n",
    "            \"last_author_institution\": last_author_inst,\n",
    "            \"pdf_url\": pdf_url,\n",
    "            **last_4_years_citations,  # Add citations per year\n",
    "            **text_data\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "        success_count += 1\n",
    "        paper_index += 1\n",
    "\n",
    "        if print_output:\n",
    "            print(f\"[{paper_index-1}] {title} | Total Citations: {citations} | DOI: {doi or 'N/A'} | Year: {publication_year}\")\n",
    "            print(\"-\" * 100)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "def render_md_dataframe(df):\n",
    "    # Convert all values to string\n",
    "    str_df = df.astype(str)\n",
    "    \n",
    "    # Get the max width of each column\n",
    "    col_widths = [max(len(str_df[col][i]) for i in range(len(df))) for col in df.columns]\n",
    "    col_widths = [max(len(col), w) for col, w in zip(df.columns, col_widths)]\n",
    "    \n",
    "    # Build header\n",
    "    header = \"| \" + \" | \".join(col.ljust(col_widths[i]) for i, col in enumerate(df.columns)) + \" |\"\n",
    "    separator = \"| \" + \" | \".join(\"-\" * col_widths[i] for i in range(len(df.columns))) + \" |\"\n",
    "    \n",
    "    # Build rows\n",
    "    rows = []\n",
    "    for i in range(len(df)):\n",
    "        row = \"| \" + \" | \".join(str_df.iloc[i, j].ljust(col_widths[j]) for j in range(len(df.columns))) + \" |\"\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Combine everything\n",
    "    md_table = \"\\n\".join([header, separator] + rows)\n",
    "    display(Markdown(md_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2eaafce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Complex brain networks: graph theoretical analysis of structural and functional systems | Total Citations: 11369 | DOI: https://doi.org/10.1038/nrn2575 | Year: 2009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[2] FSL | Total Citations: 10549 | DOI: https://doi.org/10.1016/j.neuroimage.2011.09.015 | Year: 2011\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[3] The WU-Minn Human Connectome Project: An overview | Total Citations: 5663 | DOI: https://doi.org/10.1016/j.neuroimage.2013.05.041 | Year: 2013\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[4] The minimal preprocessing pipelines for the Human Connectome Project | Total Citations: 5357 | DOI: https://doi.org/10.1016/j.neuroimage.2013.04.127 | Year: 2013\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[5] A multi-modal parcellation of human cerebral cortex | Total Citations: 4927 | DOI: https://doi.org/10.1038/nature18933 | Year: 2016\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[6] Mapping the Structural Core of Human Cerebral Cortex | Total Citations: 4230 | DOI: https://doi.org/10.1371/journal.pbio.0060159 | Year: 2008\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[7] BrainNet Viewer: A Network Visualization Tool for Human Brain Connectomics | Total Citations: 3908 | DOI: https://doi.org/10.1371/journal.pone.0068910 | Year: 2013\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[8] Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates | Total Citations: 3442 | DOI: https://doi.org/10.1073/pnas.1602413113 | Year: 2016\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[9] DPARSF: a MATLAB toolbox for “pipeline” data analysis of resting-state fMRI | Total Citations: 3408 | DOI: https://doi.org/10.3389/fnsys.2010.00013 | Year: 2010\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[10] fMRIPrep: a robust preprocessing pipeline for functional MRI | Total Citations: 3316 | DOI: https://doi.org/10.1038/s41592-018-0235-4 | Year: 2018\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| title                                                                                      | doi                                              | citations_total | publication_date | publication_year | first_author_institution           | last_author_institution                      | pdf_url                                          | 2022 | 2023 | 2024 | 2025 | abstract | introduction | methods | full_text |\n",
       "| ------------------------------------------------------------------------------------------ | ------------------------------------------------ | --------------- | ---------------- | ---------------- | ---------------------------------- | -------------------------------------------- | ------------------------------------------------ | ---- | ---- | ---- | ---- | -------- | ------------ | ------- | --------- |\n",
       "| Complex brain networks: graph theoretical analysis of structural and functional systems    | https://doi.org/10.1038/nrn2575                  | 11369           | 2009-02-04       | 2009             | Addenbrooke's Hospital             | Indiana University Bloomington               | https://doi.org/10.1038/nrn2575                  | 836  | 849  | 751  | 451  | None     | None         | None    | None      |\n",
       "| FSL                                                                                        | https://doi.org/10.1016/j.neuroimage.2011.09.015 | 10549           | 2011-09-16       | 2011             | University of Oxford               | University of Oxford                         | https://doi.org/10.1016/j.neuroimage.2011.09.015 | 1153 | 1220 | 1228 | 838  | None     | None         | None    | None      |\n",
       "| The WU-Minn Human Connectome Project: An overview                                          | https://doi.org/10.1016/j.neuroimage.2013.05.041 | 5663            | 2013-05-16       | 2013             | Washington University in St. Louis | University of Minnesota                      | https://doi.org/10.1016/j.neuroimage.2013.05.041 | 696  | 681  | 727  | 411  | None     | None         | None    | None      |\n",
       "| The minimal preprocessing pipelines for the Human Connectome Project                       | https://doi.org/10.1016/j.neuroimage.2013.04.127 | 5357            | 2013-05-10       | 2013             | Washington University in St. Louis | Wellcome Centre for Integrative Neuroimaging | https://doi.org/10.1016/j.neuroimage.2013.04.127 | 699  | 707  | 756  | 402  | None     | None         | None    | None      |\n",
       "| A multi-modal parcellation of human cerebral cortex                                        | https://doi.org/10.1038/nature18933              | 4927            | 2016-07-19       | 2016             | Washington University in St. Louis | Washington University in St. Louis           | https://doi.org/10.1038/nature18933              | 621  | 701  | 719  | 396  | None     | None         | None    | None      |\n",
       "| Mapping the Structural Core of Human Cerebral Cortex                                       | https://doi.org/10.1371/journal.pbio.0060159     | 4230            | 2008-06-24       | 2008             | University of Lausanne             | Indiana University Bloomington               | https://doi.org/10.1371/journal.pbio.0060159     | 247  | 211  | 192  | 113  | None     | None         | None    | None      |\n",
       "| BrainNet Viewer: A Network Visualization Tool for Human Brain Connectomics                 | https://doi.org/10.1371/journal.pone.0068910     | 3908            | 2013-07-04       | 2013             | Beijing Normal University          | Beijing Normal University                    | https://doi.org/10.1371/journal.pone.0068910     | 463  | 442  | 407  | 262  | None     | None         | None    | None      |\n",
       "| Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates | https://doi.org/10.1073/pnas.1602413113          | 3442            | 2016-06-28       | 2016             | Linköping University               | Linköping University                         | https://doi.org/10.1073/pnas.1602413113          | 269  | 250  | 190  | 120  | None     | None         | None    | None      |\n",
       "| DPARSF: a MATLAB toolbox for “pipeline” data analysis of resting-state fMRI                | https://doi.org/10.3389/fnsys.2010.00013         | 3408            | 2010-01-01       | 2010             | Beijing Normal University          | Beijing Normal University                    | https://doi.org/10.3389/fnsys.2010.00013         | 335  | 271  | 247  | 159  | None     | None         | None    | None      |\n",
       "| fMRIPrep: a robust preprocessing pipeline for functional MRI                               | https://doi.org/10.1038/s41592-018-0235-4        | 3316            | 2018-12-04       | 2018             | Stanford University                | Stanford University                          | https://doi.org/10.1038/s41592-018-0235-4        | 508  | 660  | 747  | 534  | None     | None         | None    | None      |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter your topic or paper title: \")\n",
    "    mode = input(\"Enter mode ('full' for full text, 'sections' for abstract+intro+methods, 'notext' for metadata only): \").strip().lower()\n",
    "    if mode not in [\"full\", \"sections\", \"notext\"]:\n",
    "        mode = \"sections\"\n",
    "    df = find_and_extract(query, n=10, mode=mode)\n",
    "   \n",
    "    render_md_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
